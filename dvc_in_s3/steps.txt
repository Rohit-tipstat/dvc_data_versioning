Building pipeline
1) create a github repo and clone it in local(add experiments)
2) Add scr folder along with all components(run them individually)
3) Add data, models, reports directories to .gitignore file
4) Now git add, commit, push


Setting up .dvc pipeline (without params)
5. Create dvc.yaml file and add stages to it
6. dvc init then do dvc repro to rest the pipeline automation (check dvc dag)
7. Now git add, commit, push

Setting up dvc pipleine (with params)
8. add params.yaml file
9. Add the params setup (mentioned below)
10. Do "dvc repro" again to test the pipeline along with the params
11. Now git add, commit, push

Experimenting with DVC:
12. pip install dvclive
13. Add the dvclive code block
14. Do "dvc exp run", it will create a new dvc.yaml (if already not there) and dvclive directory (each run will be consideredas an experiments)
15. Do "dvc exp show" on terminal to see the experiments or use extensions on VSCode (install dvc extension)
16. Do "dvc exp remove (exp-name)" to remove exp (optional) | "dvc exp apply (exp-name)" to reproduce prev code
17. Change params, re-run code (produce new experiments)
18. Now git add, commit, push


Adding a remote s3 
19. Login to AWS
20. Create an IAM user
21. Create s3
22. pip install dvc[s3]
23. pip install awscli
24. aws configure
25. dvc remote add -d dvcstore s3://bucketname
26. dvc commit-push the exp outcome that you want to kwwp
27. finally git add, commit, push